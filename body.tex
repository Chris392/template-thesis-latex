%for reference to this section
\section{Einleitung}
\label{section:Introduction}

In der Medizinischen Forschung ist es wichtig, dass Studienergebnisse mit 
fehlenden Daten sorgfältig analysiert und bearbeitet werden. Das soll verhindern, dass es zu einer Verzerrung des 
Ergebnisses kommt. Viele Medizinische Zeitschriften verlangen bereits einen korrekten Umgang mit Fehlenden Daten sowie 
eine Rechtfertigung für den gewählten statistischen Ansatz. \autocite[163]{Lee2014} 
Eine wichtige Methode zur Behandlung von fehlenden Daten ist die Multiple Imputation (MI).

Ziel dieser Arbeit ist es, einen Überblick über die MI im Medizinischen Bereich zu geben. Neben einer 
Erklärung der MI, wird auf wichtige Fragestellungen bei der Durchführung der MI eingegangen.

Ein wichtiger Teil bei der Durchführung der MI ist die Planung der MI und die Überprüfung des Datensatzes. 
Dabei wird im Forschungsblatt der Anteil von fehlenden Daten sowie die Art der fehlenden Daten erläutert. 
Des Weiteren muss die Methode der Imputation gewählt werden. Es werden einige Alternativen zur MI aufgezeigt und es 
wird auf den Vorteil von Hilfsvariablen bzw. Post-Baseline Untersuchungen eingegangen. Nach der Durchführung
kann das Ergebnis der MI überprüft werden. Hierbei werden im Forschungsblatt unterschiedliche Mittel zur 
Qualitätsfeststellung beschrieben.


\section{Multiple Imputation}
\label{section:MI}

\subsection{Anwendungsbeispiel der MI}

Angenommen es würde eine Studie über den Zusammenhang zwischen Blutdruck und dem Risiko eines Herzinfarkts geben. 
Dabei fehlen die Blutdruck Daten bei einigen Herzinfarkt-Patienten. Man kann nun aufgrund der anderen Daten die 
gesammelt wurden Rückschlüsse auf die fehlenden Daten ziehen. So können z.B. die fehlenden Blutdruck-Daten einiger 
Patienten ersetzt werden, indem andere Patienten mit gleichen Eigenschaften gesucht werden. Bei Patienten mit gleichen 
Eigenschaften (z.B. gleiches Alter, gleicher BMI) steigt auch die Wahrscheinlichkeit, dass der Blutdruck-Wert ähnlich ist. 

Allerdings kann diese Vorgehensweise aufwändig werden. Vor allem, wenn es sehr viele Variablen gibt. Es wird z.B. 
schwierig werden, einen Patienten mit genau demselben BMI, Alter, Blutdruck etc. zu finden. Daher wird in 
der MI versucht, anhand der vorhandenen Daten und einer Verteilungsfunktion eine Vermutung über den fehlenden Wert zu 
bekommen. Man könnte z.B. davon ausgehen, dass die Blutdruckwerte der Bevölkerung Normalverteilt sind. Aufgrund dieser Vermutung 
kann der Mittelwert aller Blutdruckwerte gebildet und für die fehlenden Daten eingesetzt werden. Es würde sich dabei um eine ``Single Regression`` handeln. \autocite[3]{Shrive2006}
Für Komplexere Sachverhalte ist 
dieses Vorgehen allerdings nicht ausreichend. \autocite[1089]{Donders2006}

Um den gesamten Sachverhalt besser darstellen zu können, werden z.B. mehrere voneinander abhängige Regressionsmodelle 
(Chained Equations) oder eine Mehrdimensionale Normalverteilung (Multivariate Normal Imputation) benötigt. \autocite[489]{Spratt2010} Damit 
werden mehrere Eigenschaften berücksichtigt. Für die Studie könnten die Daten z.B. mithilfe von Chained Equations imputiert werden. Im Folgenden wird
die Chained Equation Methode anhand eines einfachen Beispiels näher erläutert:

In der Chained Equation Methode werden mehrere Imputationen auf einzelnen Variablen durchgeführt. Angenommen es gibt die Variablen BMI, Alter und Blutdruck. 
In allen Variablen gibt es fehlende Daten. Zu Beginn kann für die fehlenden Daten z.B. einfach der Mittelwert eingesetzt werden. Also für alle fehlenden 
BMI-Daten wird der Mittelwert der BMI-Werte eingesetzt. Dasselbe passiert für Alter und Blutdruck. Danach wird auf jede Variable jeweils eine Imputation durchgeführt. 
Zuerst können z.B. die fehlenden BMI-Daten imputiert werden. Dazu werden zuerst die bereits vorhandenen imputierten Werte (im Falle des ersten Durchlaufs die Mittelwerte)
der BMI-Variable gelöscht. Es wird daraufhin ein Regressionsmodell mit den BMI-Werten im Verhältnis zu Alter und Blutdruck erstellt. Angenommen es wird der BMI-Wert
eines 60-Jährigen mit einem Blutdruckwert von 140-90 gesucht. Anhand des Regressionsmodells kann man nun z.B. ablesen, dass der BMI in Bezug auf Alter und Blutdruck 27 beträgt.
Dieser Wert wird nun für den fehlenden Wert eingesetzt. Dasselbe passiert mit dem Alter im Bezug auf BMI und Blutdruck und dem Blutdruck in Bezug auf Alter und BMI. Dadurch
entsteht ein neuer Datensatz mit den imputierten Werten. Auf diesen neuen Datensatz wird derselbe Vorgang nun mehrmals wiederholt. \autocite[108]{Tilling2016}
Das mehrfache Wiederholen des Vorgangs erhöht die Genauigkeit der imputierten Werte.  


\subsection{Funktionsweise der MI}

Ausgangspunkt der MI ist das Analysis Modell. Das Analysis Modell ist ein Datensatz, in welchem Daten verschiedener Variablen 
fehlen können. In der ersten Phase der MI wird aus dem Analysis Modell ein Imputation Modell erstellt. Dazu werden dem 
Analysis Model noch zusätzliche Variablen, sogenannte auxiliary variables (Hilfsvariablen) hinzugefügt. Die fehlenden 
Daten werden daraufhin z.B. mit Hilfe der Chained Equations mehrfach imputiert. Durch die mehrfache Imputation entstehen 
mehrere Vervollständigte Datensätze. In der zweiten Phase werden die Vervollständigten Datensätze analysiert und gemittelt, 
wodurch der finale Datensatz ermittelt wird. Durch die Berechnung des Standard Errors kann die Unsicherheit der Daten 
ermittelt werden. \autocite[163]{Lee2014} Im Folgenden wird auf die beiden Phasen der MI, sowie auf die Begriffe Standarderror und Bias, näher eingegangen.

\subsection{Phase 1: Mehrfache Imputation}

Die Grundsätzliche Idee der MI ist es, ein Regressionsmodell zu erstellen, dass mögliche Werte für die fehlenden Werte 
beinhaltet. Das Regressionsmodell beinhaltet also eine Reihe an Werten, die für die fehlenden Werte plausibel sind.
Aus diesem Regressionsmodell werden in Folge anhand einer Simulation randomisiert Werte gezogen. Angenommen, es 
würde sich um eine Normalverteilung handeln, dann würden die fehlenden Daten vereinfacht über folgende Formel aus \textcite[8]{Enders2017} gezogen werden:
\begin{equation}
 Y_{(mis)}\sim N(\widehat{Y}, \sigma_\varepsilon^2)
\end{equation}
„$Y_{(mis)}$ ist ein Schätzwert für den fehlenden Wert. $\sim N$ bezeichnet die Normalverteilung, $\widehat{Y}$ ist der vorhergesagte Wert aus 
einer Regressionsgleichung und $\sigma_\varepsilon^2$ ist die Residuenvarianz aus der Regression.“ \autocite[8]{Enders2017}  Die Normalverteilung
stellt die Verteilung einer Variable, z.B. des Blutdrucks im Verhältnis zu den abhängigen Variablen dar. Die Varianz definiert den Mittelwert sowie die Streuung. 
Insgesamt ist die Imputation aus einer Gleichung die Summe eines Abweichungswertes 
(Varianz) und des vorhergesagten Wertes. \autocite[8]{Enders2017}. Der Schätzwert für einen fehlenden Wert wird also berechnet, indem man einen 
Wert entsprechend der abhängigen Variablen aus dem Bereich einer Gleichung zieht. Der Bereich wird dabei durch die Varianz bestimmt, die die Unsicherheit der Daten angibt.
Das Zufällige ziehen von Schätzungen zu den fehlenden Werten wird mehrfach wiederholt, wodurch mehrere Vollständige 
Datensätze entstehen. Auf denen wird daraufhin die Analyse durchgeführt. \autocite[163 ff.]{Lee2014} Durch das 
wiederholen der Imputationen mit unterschiedlichen, plausiblen Regressions-Parametern, gleichen die Datensätze keiner 
Imputation der anderen. \autocite[8]{Enders2017} Ein Grundprinzip der MI ist es also, mehrere Annahmen über die vorhandenen Daten zu machen, 

\subsection{Phase 2: Analyse der Daten}

In der 2. Phase wird jeder der Imputierten Datensätze getrennt betrachtet. Wenn z.B. 20 Imputationen durchgeführt wurden, 
gibt es 20 Datensätze, die Schätzwerte für die fehlenden Werte beinhalten. Für jeden dieser Datensätze wird ein gemeinsamer 
Schätzwert (z.B. über das Arithmetische Mittel) und der Standard Error berechnet. Zuletzt werden die 20 Datensätze noch 
kombiniert, indem das Arithmetische Mittel der Schätzwerte sowie des Standard Errors gebildet wird. \autocite[10]{Enders2017}

\subsection{Standarderror}

Der Standarderror ist ein Maß für die Unsicherheit der 
geschätzten Werte. \autocite[1098]{Donders2006} Er ist somit auch ein Indikator für den Informationsverlust durch fehlende Daten. \autocite[1298]{Hughes2019}
Angenommen es gibt in einer Studie fehlende Blutdruckwerte. Die Blutdruckwerte werden nun 3x mithilfe verschiedener Regressionsmodellen imputiert.
Es entstehen somit 3 komplette Datensätze mit jeweils unterschiedlichen imputierten Blutdruckwerten. Ist der Mittelwert der imputierten Blutdruckwerte zwischen den 3 kompletten
Datensätzen sehr unterschiedlich, dann wird der Standarderror hoch sein. Daraus kann man schließen, dass es eine hohe Unsicherheit in der Genauigkeit der Blutdruckdaten gibt und
somit womöglich ein Bias vorhanden ist.   

\subsection{Bias}

Unter Bias versteht man einen systematischen Fehler. Dieser Fehler entsteht, 
wenn der Einfluss von Eigenschaften über- oder unterbewertet wird. \autocite[2]{Jakobsen2017} Angenommen, der BMI 
spielt keine Rolle bei der Entstehung von Herz-Kreislauferkrankungen. Sollte eine Studie den BMI als großen Faktor 
für die Entstehung von Herz-Kreislauferkrankungen miteinbeziehen, ist das Ergebnis vermutlich biased bzw. voreingenommen.

\subsection{Praktische Anwendung der MI}

Statistische Programme wie SAS und Stata unterstützen bereits MI unter der Verwendung des Conditional Regression Modells 
sowie der Joint Normal Distribution. \autocite[164]{Lee2014}. Da dieses Paper einen Allgemeinen Überblick über die MI 
geben soll, wird auf die genaue Implementierung nicht mehr eingegangen. 

Eine Implementierung der MI kann in \textcite[]{Royston2005} gefunden werden. Dort wird die Implementierung der MI in der MICE Methode 
näher erläutert. Die MICE-Methode basiert auf Chained Equations. Die Implementierung wird anhand von Ado-Dateien beschrieben.
Ado-Dateien sind Dateien, welche vom Statistik Programm Stata verwendet werden.

\subsection{Vorgehensweise MI}

Bevor die MI durchgeführt werden kann. Sollten einige wichtige Punkte geklärt werden, die in den nächsten 
Kapiteln näher erläutert werden. So stellt sich unter anderem die Frage, wie groß der Anteil an fehlenden 
Daten ist und welche Auswirkungen dies hat. (Siehe Kapitel \ref{section:missing_data}). Nach der 
Durchführung der MI sollte zu dem die Qualität der MI überprüft werden (siehe Kapitel \ref{section:qualtity}).


\section{Anteil an fehlenden Daten}
\label{section:missing_data}

Es gibt in der Forschung unterschiedliche Empfehlungen, bis zu welchem Anteil an fehlenden 
Daten zuverlässige Ergebnisse erzielt werden können. Statistische Leitartikel gehen davon aus, 
dass es ab 10\% an fehlenden Daten wahrscheinlich zu einem Bias kommen kann. Ab 40\% sollte 
das Ergebnis der MI nur mehr als Hypothese gesehen werden. Die Beweislage, die diese Grenzen 
stützt, ist allerdings gering. \autocite[63 f.]{Madley-Dowd2019}

In der Studie “The proportion of missing data should not be used to guide decisions on multiple imputation” wird 
argumentiert, dass der Anteil an fehlenden Daten nicht unbedingt ausschlaggebend für den Erfolg oder Misserfolg der 
MI steht. Viel mehr spielen die Art der fehlenden Daten und die Verwendung von Hilfsvariablen eine wichtige Rolle. 

\section{Art der fehlenden Daten}
\label{section:descriptor_of_missingness}

Nach Definition von (Little \& Rubin, 2002; Rubin, 1976) gibt es 3 verschiedene Arten von fehlenden Daten:

\subsection{MCAR: Missing Completely at Random}

Die Fehlenden Daten haben keine Verbindung zu den zu analysierenden Daten. Gründe für MCAR Daten 
können zum Beispiel ein Strom- oder Internetausfall sein. \autocite[8]{Enders2017} Angenommen es kommt zu einem 24-Stündigem Stromausfall.
Das Resultat daraus ist, dass 24-Stunden lang keine Ergebnisse von Untersuchungen gespeichert werden können. Bei dem Stromausfall
handelt es sich um ein komplett zufälliges Event, dass vermutlich alle Typen von Patienten (alt, jung, groß, klein, ...) gleichermaßen betrifft.
Man spricht daher bei den fehlenden Daten von MCAR Daten. 

\subsection{MAR: Missing at Random}

Systematische Unterschiede zwischen den fehlenden Daten und den Untersuchten Daten können erklärt 
werden. So können zum Beispiel Blutdruckwerte v.a. bei jüngeren Personen fehlen, da bei diesen 
der Blutdruck weniger oft kontrolliert wird. \autocite[157]{Sterne2009} An den vorhandenen Daten 
kann man nun erkennen, dass es bei Menschen mit Jüngerem Alter öfter zu fehlenden Blutdruckdaten 
kommt. Man könnte daher repräsentativ für die fehlenden Blutdruckdaten, die Blutdruckdaten anderer 
Junger Teilnehmer verwenden, bei welchen die Messung des Blutdrucks nicht vergessen wurde. 

\subsection{NMAR: Not Missing at Random}

Es gibt systematische Unterschiede, welche nicht anhand der Untersuchten Daten erkannt werden 
können. NMAR Daten können zum Beispiel entstehen, wenn Patienten mit hohem Blutdruck häufiger 
aufgrund von Kopfschmerzen fehlen. \autocite[157]{Sterne2009} Anhand der vorhandenen Daten kann
 man nun nicht erkennen, dass es eine Gruppe von Menschen mit Kopfschmerzen gibt, welche bei den 
 Blutdruckmessungen fehlt. 

NMAR-Daten können anhand von statistischen Tests nicht identifiziert werden. NMAR-Daten können 
also nur als solche durch vorhandenes Wissen interpretiert werden. Daher gibt es keine allgemein 
Gültige Methode für die Behandlung von NMAR-Daten. \autocite[1088]{Donders2006}

\subsection{Auswirkungen auf das Ergebnis der MI}

MAR- und NMAR Daten sind schwer zu unterscheiden. NMAR können jedoch zu einem voreingenommenen Resultat führen. Um das 
Risiko eines voreingenommenen Ergebnisses durch NMAR Daten zu verringern, kann eine Sensitivitätsanalyse angewendet 
werden. \autocite[157]{Sterne2009} 

Wenn es sich um MCAR Daten handelt, können anstatt der MI einfachere Methoden wie die Complete Case Analysis in Betracht 
gezogen werden. \autocite*[1088]{Donders2006} 

\section{Alternativen zur MI}
\label{section:alternatives}

\subsection{Complete Case Analysis (CCA)}

Bei der CCA werden Teilnehmer mit fehlenden Daten aus der Studie exkludiert. \autocite[3]{Jakobsen2017} 

In einer Simulation aus \textcite[]{VanderHeijden2006} erzielte die CCA schlechtere Ergebnisse als die MI. Für 
die Simulation wurden Daten aus einer Studie zu Lungenembolie mit 398 Subjekten verwendet. Dabei gab es 
einen Unterschiedlichen Anteil an fehlende Daten bei einigen Variablen. Bei den fehlenden Daten handelte es 
sich nicht um MCAR Daten.  Das Ergebnis der CCA schnitt dabei in allen Messgrößen im Vergleich zur single- 
und multiplen Imputation schlechter ab. Als Qualitätskriterien wurden u.a. der Standard Error sowie die 
Regressionskoeffizienten verwendet. Mögliche Qualitätskriterien werden in Kapitel XY nochmals näher erläutert.

Wenn es sich im Datensatz wie in der oben genannten Simulation nicht um MCAR-Daten handelt, dann ist das Ergebnis der 
CCA vermutlich voreingenommen. Grund dafür ist, dass die CCA systematische Unterschiede nicht 
berücksichtigt. \autocite[157]{Sterne2009} Im Fall von MAR-Daten eignet sich daher die Single- oder Multiple 
Imputation besser. \autocite[1088]{Donders2006}


\subsection{Single Imputation}

Bei der Single Imputation werden fehlende Daten nach einer Regel ersetzt. Von der Single Imputation gibt es mehrere 
Varianten. Bei der Last Observation Carried Forward (LOCF) werden fehlende Daten mit den Daten aus der letzten 
Untersuchung ersetzt. Bei der Worst Observation Carried Forward werden fehlende Daten mit dem schlechtesten untersuchten 
Ergebnis des Patienten ersetzt. Bei der Simple Mean Imputation wird der Mittelwert verwendet. Die Single Imputation hat 
die Annahme, dass fehlende Werte und in der Vergangenheit gemessene Werte identisch sind. Diese Annahme ist allerdings 
unrealistisch, weshalb diese Methode mit Bedacht eingesetzt werden soll.
\autocite[3]{Jakobsen2017}

Eine Simulation aus \textcite[]{Young-Saver2018} zeigt, dass mit der LOCF Methode ähnlich gute oder sogar bessere 
Ergebnisse erzielt werden können als mit der MI. In der Simulation wurden Daten aus einer Studie zu akutem Schlaganfall 
verwendet. Begründet wird das gute Abschneiden der LOCF u.a. mit der zeitlichen Nähe der letzten Untersuchung zu dem zu 
schätzen den Wert. Durch die zeitliche Nähe haben zeitrelevante Prozesse, wie Neuroplastizität oder Neuronale Regeneration 
(neuronale Prozesse) keinen so großen Einfluss. Zudem ist die Wahrscheinlichkeit von Vorfällen geringer, welche Einfluss 
auf die zu erhebenden Werte haben könnten. Dazu gehören z.B. Unfälle oder Herzinfarkte. \autocite[3667]{Young-Saver2018}. 
Wie gut die LOCF Methode im Vergleich zur MI abschneidet kann jedoch nicht allgemein gesagt werden und hängt maßgeblich 
von den verwendeten Daten ab. 


\subsection{Wann bietet sich der Einsatz von CCA oder Single Imputation an?}

Die Anwendung der CCA bietet sich an, wenn es sich um MCAR-Daten handelt. 
Die Single Imputation sollte mit Bedacht eingesetzt werden. Sie kann jedoch unter Umständen ähnliche gute Ergebnisse 
wie die MI erzielen. Die LOCF Methode bietet sich vor allem an, wenn es relevante, zeitnahe Untersuchungen gibt und es 
sich bei den untersuchten Variablen um Zeitrelevante Prozesse handelt. 


\section{Zusätzliche Daten}
\label{section:additional_data}

Zusätzliche Daten können den Informationsgehalt erhöhen und damit zur Reduzierung des Bias beitragen.

\subsection{Post-Baseline Untersuchungen}

Die Simulation aus \textcite[]{Young-Saver2018} zum Thema akutem Schlaganfall zeigt die Bedeutung von Post-Baseline Untersuchungen. Post-Baseline Untersuchungen sind
 Untersuchungen, die nach einem Bestimmtem Ereignis erhoben wurden. Z.B. nach einem vorgefallenem Schlaganfall. Im Falle der Studie wurde der NIH Stroke Scale 
 nach 24 Stunden und der mRS nach 7-10 Tagen erhoben. (der NIH Stroke Scale und der mRS sind beides Bewertungsskalen
  für die Symptome des Patienten). Die MI wurde einmal mit und einmal ohne Daten aus den Post-Baseline Untersuchungen 
  durchgeführt. Im Ergebnis der Simulation schnitt die Multiple Imputation mit Post-Baseline besser ab als ohne. (siehe Abbildung \ref{figure:study})

  \begin{figure*}[t]
	\centering
	\includegraphics[width=0.9\textwidth]{images/grafik_saver.png}
	\caption{
		Die MI mit Post-Baseline Variablen (orange umrahmt) schnitt bei jedem Prozentsatz an fehlenden Daten besser ab als 
		die MI ohne Post Baseline Variablen (blau umrahmt). Die Simulation wurde mittels simulierter fehlender Daten durchgeführt. Berechnet wurde der P-Value.
		Eine nähere Erläuterung dazu kann in Kapitel \ref{section:qualtity} gefunden werden. 
		Grafik aus \textcite[3667]{Young-Saver2018}, die Beschriftung sowie die blaue/orange Markierung wurde nachträglich 
		hinzugefügt.
	}
	%for reference to this figure
	\label{figure:study}
\end{figure*}

%TODO Eventl. ersten Satz löschen
\subsection{Hilfsvariablen}

Unter Hilfsvariablen (engl.: auxiliary variables) versteht man Variablen, welche dem Datensatz hinzugefügt werden, um bei der Imputation zu helfen. \autocite[211]{Graham2007}
Durch Hilfsvariablen wird die Menge an Information erhöht, wodurch im Optimalfall die Imputation verbessert werden soll.
Hilfsvariablen können z.B. auch aus anderen Studien/Datensätzen herangezogen werden.

Eine Simulation in \textcite[]{Madley-Dowd2019} zeigt die Bedeutung der Hilfsvariablen. 
Die Simulation wurde anhand von Daten aus ALSPAC (Avon Longitudinal Study of Parents and Children) 
durchgeführt. In der ALSPAC Studie wurde die Auswirkung von Rauchen während der Schwangerschaft auf den Intelligenzquotienten des Kindes untersucht. Als Variablen wurde
der IQ im Alter von 15 Jahren und ein Binärwert für das Rauchen während der Schwangerschaft verwendet. Als Hilfsvariablen wurde der IQ im Alter von 8 Jahren, die Verständlichkeit 
und der Redefluss im Alter von 9 Jahren, ein Binärwert für das Vorhandensein von Lernschwierigkeiten sowie die Mathematik- und Lesefähigkeiten des Kindes im 6. Schuljahr verwendet. 
Unter der Miteinbeziehung der Hilfsvariablen bei der MI verringerte sich der Standard Error im Vergleich zur MI ohne Hilfsvariablen von 0.504 auf 0.461. Der FMI (Fraction of Missing Information)
verringerte sich von 0.724 auf 0.664. \autocite[71]{Madley-Dowd2019} Der FMI ist ein Parameter, der den Verlust an Informationen darstellt. Der FMI kann zwischen 0 und 1 liegen, 
ein niedriger FMI ist anzustreben.
\autocite[65]{Madley-Dowd2019} Eine nähere Erläuterung des FMIs kann in \textcite[]{Madley-Dowd2019} gefunden werden. 


Man sieht anhand der Reduktion von FMI und Standarderror, dass sich Hilfsvariablen positiv auf die MI auswirken können. Ausschlaggebend für den Effekt von Hilfsvariablen
ist u.a. ob die Hilfsvariable genügend Information über die fehlenden Werte bereitstellt. \autocite[1302]{Hughes2019} Ein Indikator für den Effekt einer Hilfsvariable auf 
die MI ist die Reduktion des Standarderrors. 

In der Studie von \textcite[]{Madley-Dowd2019} 
reduzierte sich der Standarderror bei der Hinzugabe der Hilfsvariable 
``IQ im Alter von 8 Jahren`` um 7.65\%. Wurde die Hilfsvariable ``Learning Disabilities``  hinzugefügt, erhöhte sich der Standarderror um 0,8\%. \autocite[71]{Madley-Dowd2019} 
Dies zeigt, dass nicht alle Hilfsvariablen zwingend den Informationsgehalt und damit die Genauigkeit des Ergebnisses verbessern. 
Eine sorgfältige Überprüfung/Auswahl von Hilfsvariablen ist daher von Vorteil. 

Neben dem Standarderror, gibt es noch weitere Qualitätskriterien für die MI. Einige davon werden im nächsten Kapitel
(Kapitel \ref{section:qualtity}) näher beschrieben.


\section{Qualitätsfeststellung MI}
\label{section:qualtity}

\subsection{Simulierte fehlende Daten und P-Value}

Eine einfache Methode zur Qualitätsüberprüfung ist es, einen vollständigen Datensatz zu nehmen und die fehlenden Daten zu 
simulieren. Nach dieser Vorgehensweise wurde auch die Simulation aus \textcite[]{Young-Saver2018} durchgeführt. Hierbei wurde 
aus dem Vollständigen Datensatz auf Basis eines randomisierten Verfahrens Daten gelöscht. Daraus folgt, dass man nun die 
imputierten Daten mit den Daten des Vollständigen Datensatzes vergleichen kann. Ein möglicher Vergleich wäre z.B. die 
Bestimmung der exakten Übereinstimmungsrate. Hierbei wird der Anteil von exakten Übereinstimmungen zwischen den imputierten 
und originalen Werten bestimmt. Des Weiteren kann Spearmans Korrelationskoeffizient, oder die Mittlere (Absolute) Abweichung 
bestimmt werden. \autocite[3664]{Young-Saver2018} 

Ein weiterer Wert, mit dem der Unterschied zwischen vollständigem und imputiertem Datensatz verglichen werden kann, ist der P-Value.
Der P-Value gibt an, wie groß der Unterschied zwischen zwei Datensätzen ist. Je nachdem, wie groß der gewählte Threshold ist,
kann daraufhin eine Aussage darüber getroffen werden, ob die beiden Datensätze signifikant oder nicht signifikant unterschiedlich
sind. 

Signifikante Unterschiede zwischen vollständigem und imputiertem Datensatz sind ein Indikator für einen vorhandenen Bias.

\subsection{Sensitivitätsanalyse}

Vor der Durchführung der MI sollte eine Vermutung über die Art der fehlenden Daten gemacht werden. Sind die Daten MAR, MNAR 
oder MCAR? Angenommen es gibt eine Studie, die den Zusammenhang zwischen Blutdruck und Herz-Kreislauferkrankungen untersucht. 
Sollte ein Teil der Patienten diese Studie vorzeitig verlassen, könnte man vermuten, dass dies komplett zufällig geschieht. 
Die Daten wären somit MCAR. Es könnte aber auch sein, dass einige Patienten die Studie aufgrund von Kopfschmerzen wegen zu 
hohen Blutdrucks verlassen. Damit gäbe es einen systematischen Zusammenhang und die Daten währen MAR oder MNAR. In vielen 
Studien ist es schwer, eine sichere Vermutung über die Art der fehlenden Daten zu treffen. Mit Sensitivitätsanalysen können 
mehrere Vermutungen über die Art der fehlenden Daten überprüft werden. \autocite[2815]{Cro2020}

Im Allgemeinen gibt es 2 Varianten der Sensitivitätsanalyse: $\delta$-basiert und referenzbasiert. In der $\delta$-basierten Variante 
wird dem zu erwarteten Wert noch ein Offset Variable $\delta$(Delta) hinzugefügt, welche den Einfluss von 
fehlenden/nicht-beobachteten Teilnehmern bewertet.  In der Referenzbasierten Sensitivitätsanalyse werden Werte aus 
anderen Gruppen des Versuchs imputiert, welche Referenz zu den Beobachteten Werten beinhaltet. \autocite[2815]{Cro2020} 
Eine praktische Beschreibung der Durchführung der Sensitivitätsanalyse in Verbindung mit der MI kann in 
\textcite[]{Cro2020} gefunden werden.

\section{Fazit}

Eine sorgfältige Planung und Durchführung der Imputation ist wichtig, damit es nicht zu verzerrten Ergebnissen kommt. 
Im ersten Schritt sollte der verwendete Datensatz überprüft werden. Bei den Verwendeten Daten sollte der Anteil an fehlenden 
Daten nicht zu hoch sein. In der Forschung gibt es jedoch Unterschiedliche Vorgaben, welche Menge an fehlenden Daten in 
Ordnung ist. Mehr Forschung wäre hier von Vorteil. Bei der Art der fehlenden Daten sollte es sich möglichst um MAR Daten 
handeln. 

Im Zweiten Schritt sollte die zu verwendende Methode für die Behandlung fehlender Daten, sowie die Verwendung von zusätzlichen Variablen geplant 
werden. 
Handelt es sich um MCAR Daten, kann der Einsatz einer CCA überlegt werden. Gibt es relevante, zeitnahe Untersuchungen 
zu den fehlenden Daten, kann auch die Verwendung der Single Imputation in der LOCF-Variante gute Ergebnisse erzielen. 
Das Hinzufügen von Post-Baseline Untersuchungen oder Hilfsvariablen kann das Resultat der MI verbessern. 

Nach der Durchführung der MI ist es zu empfehlen, eine Sensitivitätsanalyse durchzuführen. Vor allem, wenn es sich nicht 
sicher um MAR Daten handelt. Der Standard Error sollte nicht zu hoch sein, da hohe Werte auf einen Bias hinweisen können.

MI ist eines der wichtigsten Werkzeuge für die Behandlung von fehlenden Daten in vielen verschiedenen Bereichen. 
Wer sich z.B. mit Statistik oder AI beschäftigt, sollte einen Überblick über MI haben. MI ist ein komplexes Thema und 
auch dieses Forschungsblatt konnte nur einen kleinen Überblick zum Thema MI geben. Es ist daher von Vorteil, dass die 
meisten Statistischen Programme bereits MI unterstützen und so den Einstieg in die MI vereinfachen. 


